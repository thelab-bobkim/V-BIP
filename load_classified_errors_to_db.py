#!/usr/bin/env python3
"""
V-BIP 2.3 ë¶„ë¥˜ëœ ì—ëŸ¬ì½”ë“œ PostgreSQL DB ì ì¬
2,804ê°œ ì—ëŸ¬ì½”ë“œë¥¼ error_codes í…Œì´ë¸”ì— ì¼ê´„ ì‚½ì…
"""

import json
import psycopg2
from datetime import datetime

# Database connection
DB_CONFIG = {
    'dbname': 'vbip',
    'user': 'vbip_user',
    'password': 'vbip_password_2024',
    'host': 'localhost',
    'port': 5432
}

def load_classified_errors_to_db(json_file: str):
    """ë¶„ë¥˜ëœ ì—ëŸ¬ì½”ë“œë¥¼ DBì— ì ì¬"""
    
    print("ğŸš€ V-BIP 2.3 ë¶„ë¥˜ ì—ëŸ¬ì½”ë“œ DB ì ì¬ ì‹œì‘...")
    print(f"ğŸ“‚ ì…ë ¥ íŒŒì¼: {json_file}\n")
    
    # Load classified errors
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    classified_errors = data['classified_errors']
    total_errors = len(classified_errors)
    
    print(f"âœ… {total_errors}ê°œ ë¶„ë¥˜ ì—ëŸ¬ì½”ë“œ ë¡œë“œ ì™„ë£Œ\n")
    
    # Connect to database
    conn = psycopg2.connect(**DB_CONFIG)
    cur = conn.cursor()
    
    print("ğŸ“¦ DB ì—°ê²° ì„±ê³µ\n")
    
    # Truncate existing error_codes (ì„ íƒì‚¬í•­)
    # cur.execute("TRUNCATE TABLE error_codes CASCADE;")
    # print("ğŸ—‘ï¸  ê¸°ì¡´ error_codes í…Œì´ë¸” ì´ˆê¸°í™”\n")
    
    # Insert errors into error_patterns table
    insert_query = """
    INSERT INTO error_patterns (
        error_code, error_type, error_name, error_description, 
        symptom, root_cause, troubleshooting_steps, 
        auto_fix_script, auto_fix_enabled, 
        severity, avg_resolution_minutes, 
        occurrence_frequency, success_rate_percent, 
        resolution_level, ai_confidence_score, 
        classification_reason, is_ai_classified, ai_model_version,
        created_at, last_updated
    ) VALUES (
        %s, %s, %s, %s, 
        %s, %s, %s, 
        %s, %s, 
        %s, %s, 
        %s, %s, 
        %s, %s, 
        %s, %s, %s,
        %s, %s
    )
    ON CONFLICT (error_code) DO UPDATE SET
        error_name = EXCLUDED.error_name,
        error_description = EXCLUDED.error_description,
        severity = EXCLUDED.severity,
        resolution_level = EXCLUDED.resolution_level,
        ai_confidence_score = EXCLUDED.ai_confidence_score,
        classification_reason = EXCLUDED.classification_reason,
        auto_fix_enabled = EXCLUDED.auto_fix_enabled,
        auto_fix_script = EXCLUDED.auto_fix_script,
        is_ai_classified = EXCLUDED.is_ai_classified,
        last_updated = NOW()
    """
    
    inserted_count = 0
    updated_count = 0
    
    for idx, error in enumerate(classified_errors, 1):
        try:
            code = error['code']
            message = error.get('message', '')[:200]  # error_name ìµœëŒ€ 200ì
            explanation = error.get('explanation', '')  # error_description (TEXT)
            
            severity = error.get('severity_level', 'Medium')
            resolution_level = error.get('resolution_level', 2)
            confidence = error.get('ai_confidence_score', 70)
            reason = error.get('classification_reason', '')
            
            auto_fix = error.get('auto_fix_enabled', False)
            auto_fix_script = error.get('auto_fix_script', None)
            
            resolution_time = error.get('estimated_resolution_time', 30)
            
            # Check if error code already exists
            cur.execute("SELECT error_code FROM error_patterns WHERE error_code = %s", (code,))
            exists = cur.fetchone() is not None
            
            # Insert into error_patterns table
            cur.execute(insert_query, (
                code, 'NetBackup', message, explanation,
                message, reason, explanation,
                auto_fix_script, auto_fix,
                severity, resolution_time,
                0, 0.0,  # occurrence_frequency, success_rate
                resolution_level, float(confidence),
                reason, True, 'keyword-v1',
                datetime.now(), datetime.now()
            ))
            
            if exists:
                updated_count += 1
            else:
                inserted_count += 1
            
            if idx % 500 == 0:
                print(f"[{idx}/{total_errors}] ì§„í–‰ ì¤‘... (ì‹ ê·œ: {inserted_count}, ì—…ë°ì´íŠ¸: {updated_count})")
                conn.commit()  # Commit every 500 rows
            
        except Exception as e:
            print(f"âš ï¸  ì—ëŸ¬ì½”ë“œ {code} ì‚½ì… ì‹¤íŒ¨: {e}")
            continue
    
    # Final commit
    conn.commit()
    
    print(f"\n{'='*70}")
    print(f"âœ… DB ì ì¬ ì™„ë£Œ!")
    print(f"{'='*70}")
    print(f"ğŸ“Š í†µê³„:")
    print(f"  - ì´ ì²˜ë¦¬: {total_errors}ê°œ")
    print(f"  - ì‹ ê·œ ì‚½ì…: {inserted_count}ê°œ")
    print(f"  - ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
    print(f"{'='*70}\n")
    
    # Verify insertion
    cur.execute("SELECT COUNT(*) FROM error_patterns")
    total_in_db = cur.fetchone()[0]
    
    cur.execute("SELECT resolution_level, COUNT(*) FROM error_patterns GROUP BY resolution_level ORDER BY resolution_level")
    level_stats = cur.fetchall()
    
    print(f"ğŸ“Š DB ê²€ì¦:")
    print(f"  - ì „ì²´ ì—ëŸ¬ì½”ë“œ: {total_in_db}ê°œ")
    for level, count in level_stats:
        print(f"  - Level {level}: {count}ê°œ ({count/total_in_db*100:.1f}%)")
    
    cur.close()
    conn.close()
    
    print(f"\nâœ… DB ì ì¬ ë° ê²€ì¦ ì™„ë£Œ!")

if __name__ == '__main__':
    JSON_FILE = '/home/user/V-BIP/classified_all_errors_keyword.json'
    load_classified_errors_to_db(JSON_FILE)
